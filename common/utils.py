# utils.py
# -*- coding: utf-8 -*-
"""
Fonctions utilitaires g√©n√©rales (dates, formats, logs, etc.).
"""

from datetime import datetime, timedelta, time
from pathlib import Path
import pandas as pd
import zipfile
import shutil
import json

# ------------------------------------------------------
# ‚è∞ Gestion des dates
# ------------------------------------------------------

def format_date_to_str(date_obj: datetime) -> str:
    """
    Formate un datetime en cha√Æne 'YYYY-MM-DD'.

    Param√®tre :
        date_obj (datetime) : objet datetime

    Retour :
        str : date format√©e
    """
    return date_obj.date().strftime("%Y-%m-%d")

def format_str_to_date(date_str: str) -> datetime:
    """
    Formate un string de date au format 'YYYY-MM-DD' en datetime.

    Param√®tre :
        date_str (str) : date au format 'YYYY-MM-DD'

    Retour :
        datetime : date format√©e
    """
    return datetime.strptime(date_str, "%Y-%m-%d")

def yesterday() -> datetime:
    """
    Retourne la date d'hier.

    Retour :
        date_obj (datetime) : date d'hier
    """
    today = datetime.now().date()
    yesterday_date = today - timedelta(days=1)
    yesterday_time = time(0, 0)
    return datetime.combine(yesterday_date, yesterday_time)

def next_day(current_day: datetime) -> datetime:
    """
    Retourne la date du jour suivant.

    Param√®tre :
        current_day (datetime) : date courante 'YYYY-MM-DD'

    Retour :
        date_obj (datetime) : date du jour suivant
    """
    return current_day + timedelta(days=1)

# ------------------------------------------------------
# üßæ Gestion g√©n√©rique de logs et chemins
# ------------------------------------------------------

def print_section(title: str):
    """
    Affiche une section lisible dans la console.
    """
    print(f"\n{'='*60}\n{title}\n{'='*60}")

def resolve_path(base: Path, sub: str | Path) -> Path:
    """
    R√©sout un chemin relatif √† un r√©pertoire de base.

    Param√®tres :
        base (Path) : dossier racine
        sub (str | Path) : sous-chemin

    Retour :
        Path : chemin absolu combin√©
    """
    return base / sub

# ------------------------------------------------------
# üìÅ Gestion de dossiers et fichiers
# ------------------------------------------------------

def ensure_folder(folder_path: str | Path):
    """
    Cr√©e le dossier sp√©cifi√© s‚Äôil n‚Äôexiste pas.

    Param√®tre :
        folder_path (str | Path) : chemin du dossier √† cr√©er
    """
    path = Path(folder_path)
    path.mkdir(parents=True, exist_ok=True)
    return path

def cleanup_folders(folder_paths: list):
    """
    Supprime le dossier sp√©cifi√©.

    Param√®tre :
        folder_paths (list) : liste des chemins des dossiers √† supprimer
    """
    for folder in folder_paths:
        if folder.exists() and folder.is_dir():
            shutil.rmtree(folder)
            print(f"\nüßπ Dossier temporaire supprim√© : {folder}")

def save_json(data: dict, date_str: str, interval_folder: str) -> Path:
    """
    Sauvegarde un dictionnaire JSON dans le dossier appropri√©.

    Param√®tres :
        data (dict) : donn√©es JSON √† sauvegarder
        date_str (str) : date au format 'YYYY-MM-DD'
        interval_folder (str) : chemin vers le dossier de stockage
                                (FOLDER_1H ou FOLDER_30MIN)

    Retour :
        Path : chemin complet du fichier sauvegard√©
    """
    ensure_folder(interval_folder)
    file_path = Path(interval_folder) / f"courbe_{date_str}.json"
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    return file_path

def clean_csv_columns(source_csv: Path, columns_map: dict) -> Path:
    """
    Nettoie et renomme des colonnes d'un fichier CSV en fonction d'un mapping fourni,
    puis remplace directement le fichier CSV original par la version nettoy√©e.

    Cette fonction :
    - charge un fichier CSV,
    - v√©rifie la pr√©sence des colonnes sp√©cifi√©es dans le dictionnaire de mapping,
    - extrait uniquement ces colonnes,
    - renomme les colonnes selon le mapping,
    - √©crase le fichier d'entr√©e avec le CSV nettoy√© (s√©parateur ;),
    - retourne le chemin du fichier CSV modifi√©.

    Param√®tres
    ----------
    source_csv : Path
        Chemin du fichier CSV source (sera √©cras√©).

    columns_map : dict
        Dictionnaire {ancien_nom: nouveau_nom}
        Exemple : {"Time": "datetime", "Production (W)": "production"}

    Retour
    ------
    Path
        Chemin du fichier CSV nettoy√© (identique √† l'entr√©e).
    """

    # Lecture du CSV original
    df = pd.read_csv(source_csv)

    # Validation des colonnes
    missing = [col for col in columns_map.keys() if col not in df.columns]
    if missing:
        raise RuntimeError(
            f"Colonnes manquantes dans le fichier CSV : {missing}"
        )

    # S√©lection et renommage
    df_clean = df[list(columns_map.keys())].rename(columns=columns_map)

    # √âcrasement du fichier source
    df_clean.to_csv(source_csv, sep=";", index=False)

    return source_csv


def append_csvs_with_resampling(csv_paths: list[Path],
                                csv_30min: Path,
                                csv_1h: Path):
    """
    Ajoute plusieurs CSV bruts et met √† jour uniquement
    les fichiers resampl√©s 30 min et 1h par concat√©nation.

    Param√®tres
    ----------
    csv_paths : list[Path]
        Liste des chemins des fichiers CSV √† ajouter.
        Chaque CSV doit contenir au minimum :
        - datetime : horodatage
        - production : valeur num√©rique
    csv_30min : Path
        Chemin du fichier contenant les donn√©es moyenn√©es toutes les 30 minutes.
    csv_1h : Path
        Chemin du fichier contenant les donn√©es moyenn√©es toutes les 60 minutes.

    Retour
    ------
    None
    """

    # -----------------------------------------------------------
    # 1) Charger les nouveaux CSV bruts
    # -----------------------------------------------------------
    dfs = []
    for p in csv_paths:
        df = pd.read_csv(p, sep=";")
        df["datetime"] = pd.to_datetime(df["datetime"])
        dfs.append(df)

    df_new = pd.concat(dfs, ignore_index=True)
    df_new = df_new.set_index("datetime").sort_index()

    # -----------------------------------------------------------
    # 2) Resampling des nouvelles donn√©es
    # -----------------------------------------------------------
    df_new_30min = (
        df_new.resample("30min")
        .mean(numeric_only=True)
        .dropna()
    )

    df_new_1h = (
        df_new.resample("1h")
        .mean(numeric_only=True)
        .dropna()
    )
    df_new_1h = df_new_1h[df_new_1h.index.minute == 0]

    # -----------------------------------------------------------
    # 3) Charger l'existant et concat√©ner
    # -----------------------------------------------------------

    # ---- 30 min ----
    if csv_30min.exists():
        df_old_30 = pd.read_csv(csv_30min, sep=";", parse_dates=["datetime"])
        df_old_30 = df_old_30.set_index("datetime")
        df_30 = pd.concat([df_old_30, df_new_30min])
        df_30 = df_30[~df_30.index.duplicated(keep='last')]  # supprime doublons
        df_30 = df_30.sort_index()
    else:
        df_30 = df_new_30min

    # ---- 1 heure ----
    if csv_1h.exists():
        df_old_1h = pd.read_csv(csv_1h, sep=";", parse_dates=["datetime"])
        df_old_1h = df_old_1h.set_index("datetime")
        df_1h_final = pd.concat([df_old_1h, df_new_1h])
        df_1h_final = df_1h_final[~df_1h_final.index.duplicated(keep='last')]
        df_1h_final = df_1h_final.sort_index()
    else:
        df_1h_final = df_new_1h

    # -----------------------------------------------------------
    # 4) Sauvegarde finale
    # -----------------------------------------------------------
    df_30.to_csv(csv_30min, sep=";", index_label="datetime")
    df_1h_final.to_csv(csv_1h, sep=";", index_label="datetime")

    print(f"‚è±Ô∏è Mise √† jour du fichier 30 minutes : {csv_30min}")
    print(f"‚è±Ô∏è Mise √† jour du fichier 1 heure : {csv_1h}")


def append_csvs_to_clean_csv(csv_paths: list[Path], clean_csv: Path):
    """
    Concat√®ne plusieurs CSV en un fichier CSV unique (clean_csv).
    Cr√©e clean_csv si inexistant.

    Param√®tres :
        csv_paths : liste de chemins vers les CSV √† ajouter
        clean_csv : chemin du CSV de sortie

    Retour :
        None
    """
    dfs = []
    for p in csv_paths:
        dfs.append(pd.read_csv(p))
    df_all = pd.concat(dfs, ignore_index=True)

    if clean_csv.exists():
        df_existing = pd.read_csv(clean_csv)
        df_all = pd.concat([df_existing, df_all], ignore_index=True)

    df_all.to_csv(clean_csv, index=False)
    print(f"üßæ Donn√©es ajout√©es √† {clean_csv}")


def resampled_data_exists_for_date(target_date: datetime,
                                   csv_30min: Path,
                                   csv_1h: Path) -> bool:
    """
    V√©rifie si les donn√©es resampl√©es (30 min et 1h) existent d√©j√†
    pour la journ√©e target_date dans les fichiers csv_30min et csv_1h.

    R√®gles :
    - 30 min : il doit exister au moins les 24 timestamps horaires (HH:00)
    - 1h : les 24 timestamps horaires doivent exister (HH:00)

    Param√®tres
    ----------
    target_date : datetime
        La date √† v√©rifier
    csv_30min : Path
        Chemin du fichier CSV contenant les donn√©es resampl√©es 30 min
    csv_1h : Path
        Chemin du fichier CSV contenant les donn√©es resampl√©es 1h

    Retour
    ------
    bool
        True si les donn√©es existent d√©j√†, False sinon
    """

    day_start = datetime.combine(target_date.date(), datetime.min.time())
    expected_hours = [day_start + timedelta(hours=h) for h in range(24)]

    # -----------------------------------------------------------
    # V√©rification fichier 1h
    # -----------------------------------------------------------
    if not csv_1h.exists():
        return False

    df_1h = pd.read_csv(csv_1h, sep=";", parse_dates=["datetime"])
    df_day_1h = df_1h[(df_1h["datetime"].dt.date == target_date.date())]

    if df_day_1h.empty:
        return False

    # Timestamps attendus : toutes les heures
    found_hours = set(df_day_1h["datetime"])
    if not all(h in found_hours for h in expected_hours):
        return False

    # -----------------------------------------------------------
    # V√©rification fichier 30 min
    # -----------------------------------------------------------
    if not csv_30min.exists():
        return False

    df_30 = pd.read_csv(csv_30min, sep=";", parse_dates=["datetime"])
    df_day_30 = df_30[(df_30["datetime"].dt.date == target_date.date())]

    if df_day_30.empty:
        return False

    # V√©rifier qu'il existe au moins une donn√©e par heure
    hours_with_data = set(df_day_30["datetime"].dt.hour)

    expected_hours_set = set(range(24))
    if not expected_hours_set.issubset(hours_with_data):
        return False

    return True


# ------------------------------------------------------
# üì¶ Gestion des archives ZIP
# ------------------------------------------------------

def add_file_to_zip(tmp_file: Path, zip_path: Path, target_date: datetime):
    """
    Ajoute un fichier dans une archive ZIP en le renommant selon la date cible.

    Le nom interne dans le ZIP est : "prod_<YYYY-MM-DD>.csv"
    via la fonction format_date_to_str().

    Param√®tres :
        tmp_file (Path) : chemin du fichier temporaire local
        zip_path (Path) : chemin de l‚Äôarchive ZIP
        target_date (datetime) : date utilis√©e pour g√©n√©rer le nouveau nom
    """

    # --- Conversion de date en texte ---
    new_name = "prod_" + format_date_to_str(target_date) + ".csv"

    # --- Ajout dans le ZIP ---
    with zipfile.ZipFile(zip_path, "a", zipfile.ZIP_DEFLATED) as zipf:
        zipf.write(tmp_file, arcname=new_name)

    print(f"üì¶ Fichier ajout√© dans l‚Äôarchive sous : {new_name}")

def extract_zip_file_list(zip_path: Path) -> list[str]:
    """
    Liste les fichiers contenus dans une archive ZIP.

    Param√®tre :
        zip_path (Path) : chemin de l‚Äôarchive ZIP

    Retour :
        list[str] : liste des chemins internes des fichiers contenus dans le ZIP
    """
    if not zip_path.exists():
        return []
    with zipfile.ZipFile(zip_path, "r") as zipf:
        return zipf.namelist()

def read_csv_from_zip(zip_path: Path, zip_filename: str) -> pd.DataFrame:
    """
    Extrait et lit un fichier CSV contenu dans une archive ZIP.

    Parameters
    ----------
    zip_path : Path
        Chemin vers l'archive ZIP contenant un fichier CSV.
    zip_filename : str
        Nom du fichier CSV.

    Returns
    -------
    pd.DataFrame
        Le contenu du CSV sous forme de DataFrame.

    Raises
    ------
    FileNotFoundError
        Si l'archive ZIP n'existe pas.
    ValueError
        Si aucun fichier CSV n'est trouv√© dans l'archive.
    """
    zip_path = Path(zip_path)

    if not zip_path.exists():
        raise FileNotFoundError(f"L'archive ZIP n'existe pas : {zip_path}")

    with zipfile.ZipFile(zip_path, 'r') as z:
        # Trouver le fichier CSV dans le ZIP
        csv_file = [f for f in z.namelist() if f==zip_filename]

        if not csv_file:
            raise ValueError(f"Le fichier {zip_filename} n'a pas √©t√© trouv√© dans l'archive : {zip_path}")

        with z.open(zip_filename) as csv_file:
            try:
                return pd.read_csv(csv_file, encoding='utf-8', sep=";")
            except UnicodeDecodeError:
                # Tentative alternative automatique
                return pd.read_csv(csv_file, encoding="latin-1", sep=";")

def check_json_in_archive(zip_path:Path, date_str: str, interval_folder: str) -> bool:
    """
    V√©rifie si un fichier JSON pour une date est d√©j√† pr√©sent dans l'archive.

    Param√®tres :
        zip_path (Path) : Chemin du fichier ZIP.
        date_str (str) : date au format 'YYYY-MM-DD'
        interval_folder (str) : 'conso_1h' ou 'conso_30min'

    Retour :
        bool : True si le fichier existe dans l'archive, False sinon
    """
    zip_files = extract_zip_file_list(zip_path)
    json_name = f"{interval_folder}/courbe_{date_str}.json"
    return json_name in zip_files

def extract_csv_from_zip(zip_path: Path, dest_folder: Path) -> Path:
    """
    Extrait le CSV contenu dans un ZIP dans dest_folder.

    Param√®tres :
        zip_path : chemin du fichier ZIP
        dest_folder : chemin vers le dossier de destination du CSV

    Retour :
        chemin du CSV extrait
    """
    with zipfile.ZipFile(zip_path, 'r') as zipf:
        csv_names = [f for f in zipf.namelist() if f.lower().endswith('.csv')]
        if not csv_names:
            raise RuntimeError(f"Aucun CSV trouv√© dans {zip_path}")
        csv_name = csv_names[0]
        Path.mkdir(dest_folder, exist_ok=True)
        zipf.extract(csv_name, path=dest_folder)
        extracted_path = dest_folder.joinpath(csv_name)
    return extracted_path