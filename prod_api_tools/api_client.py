# -*- coding: utf-8 -*-
"""
api_client.py

Outils bas-niveau pour interagir avec l‚ÄôAPI Hoymiles.

Fonctionnalit√©s :
- T√©l√©charge les fichiers ZIP bruts pour une date donn√©e
- Rafra√Æchit le token automatiquement si n√©cessaire
- Ajoute les nouveaux CSV dans le jeu de donn√©es principal et dans l‚Äôarchive
"""

from os import getenv
from pathlib import Path
import tempfile
import zipfile
import shutil
from datetime import datetime
from typing import Optional
import requests
from dotenv import load_dotenv, set_key
from time import sleep
import json
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.chrome.options import Options

from common.config import ROOT_PATH
from common.utils import format_date_to_str, add_file_to_zip, extract_csv_from_zip, clean_csv_columns, append_csvs_to_clean_csv, append_csvs_with_resampling, resampled_data_exists_for_date, read_csv_from_zip
from prod_api_tools.config import LOGIN_PAGE, USERNAME, PASSWORD, TIMEOUT, DATA_FOLDER, API_BASE_URL, CSV_30MIN, CSV_1H


# Charger .env si pr√©sent (utile en local)
load_dotenv()

# ---------------------------------------------------------------------
# Helpers pour token
# ---------------------------------------------------------------------

def _current_token() -> Optional[str]:
    """Retourne le token HOYMILES_TOKEN depuis .env ou l'environnement."""
    load_dotenv(override=True)  # recharge le .env √† chaque appel
    return getenv("HOYMILES_TOKEN")

def safe_find_multiple(driver, selectors):
    """Essaie plusieurs s√©lecteurs CSS/XPath en renvoyant le premier √©l√©ment trouv√©."""
    for sel_type, sel in selectors:
        try:
            if sel_type == "css":
                return driver.find_element(By.CSS_SELECTOR, sel)
            elif sel_type == "xpath":
                return driver.find_element(By.XPATH, sel)
        except Exception:
            continue
    return None

def get_token(headless=True):
    """Effectue la connexion et retourne le token Hoymiles."""
    chrome_opts = Options()
    if headless:
        chrome_opts.add_argument("--headless=new")
        chrome_opts.add_argument("--no-sandbox")
        chrome_opts.add_argument("--disable-dev-shm-usage")

    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=chrome_opts)
    wait = WebDriverWait(driver, TIMEOUT)
    driver.get(LOGIN_PAGE)

    try:
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.ant-layout")))
    except TimeoutException:
        print("‚ö†Ô∏è Timeout initial : page non charg√©e compl√®tement.")

    username_input = safe_find_multiple(driver, [
        ("css", "input[name='user_name']"),
        ("css", "input[type='text']"),
        ("xpath", "//input[contains(@placeholder, 'user')]"),
    ])
    password_input = safe_find_multiple(driver, [
        ("css", "input[type='password']"),
        ("xpath", "//input[@type='password']"),
    ])

    if not username_input or not password_input:
        driver.quit()
        raise RuntimeError("‚ùå Impossible de trouver les champs login/password.")

    username_input.clear()
    username_input.send_keys(USERNAME)
    password_input.clear()
    password_input.send_keys(PASSWORD)
    password_input.send_keys(Keys.ENTER)

    token = None
    for _ in range(15):  # max 15s
        sleep(1)
        try:
            storage = driver.execute_script("return Object.assign({}, window.localStorage);")
            for key in ["token", "access_token", "authorization", "auth_token", "userToken"]:
                if key in storage:
                    token = storage[key]
                    break
            if not token:
                for v in storage.values():
                    try:
                        parsed = json.loads(v)
                        if isinstance(parsed, dict) and "token" in parsed:
                            token = parsed["token"]
                            break
                    except Exception:
                        continue
            if token:
                break
        except Exception:
            continue

    if not token:
        # Cookies de secours
        for c in driver.get_cookies():
            if "token" in (c.get("name") or "").lower():
                token = c.get("value")
                break

    driver.quit()
    return token

def save_token(token: str) -> None:
    """
    Sauvegarde le token :
    - en local : √©crit (ou remplace) la variable HOYMILES_TOKEN dans .env
    - dans GitHub Actions : √©crit dans le fichier $GITHUB_ENV (s'il existe)
    """
    if getenv("GITHUB_ACTIONS") is None:
        env_path = ROOT_PATH.joinpath(".env")
        lines = []
        if env_path.exists():
            with open(env_path, "r", encoding="utf-8") as fh:
                lines = fh.readlines()
        with open(env_path, "w", encoding="utf-8") as fh:
            found = False
            for line in lines:
                if line.strip().startswith("HOYMILES_TOKEN="):
                    fh.write(f"HOYMILES_TOKEN={token}\n")
                    found = True
                else:
                    fh.write(line)
            if not found:
                fh.write(f"HOYMILES_TOKEN={token}\n")
        print(f"üíæ Token mis √† jour dans {env_path}")
    else:
        gha_env = getenv("GITHUB_ENV")
        if gha_env:
            with open(gha_env, "a", encoding="utf-8") as fh:
                fh.write(f"HOYMILES_TOKEN={token}\n")
            print("üíæ Token export√© dans $GITHUB_ENV")
        else:
            print("‚ö†Ô∏è $GITHUB_ENV introuvable ‚Äî token non export√©.")

def refresh_token(mode: str = "local") -> Optional[str]:
    """
    Rafra√Æchit le token Hoymiles directement en appelant la fonction get_token().

    Param√®tres
    ----------
    mode : str
        - "local" : met √† jour le fichier .env avec le nouveau token.
        - "gha" : exporte le token vers l'environnement GitHub Actions (GITHUB_ENV).

    Retour
    ------
    str | None
        Le token r√©cup√©r√©, ou None en cas d'√©chec.
    """
    try:
        token = get_token(headless=True)
    except Exception as e:
        print(f"‚ùå Erreur lors du rafra√Æchissement du token : {e}")
        return None

    if not token:
        print("‚ùå Aucun token trouv√© apr√®s tentative de connexion Hoymiles.")
        return None

    print("‚úÖ Token r√©cup√©r√© avec succ√®s.")

    if mode == "local":
        # On suppose que le .env est √† la racine du projet
        env_path = Path(__file__).resolve().parents[1] / ".env"
        if not env_path.exists():
            print(f"‚ö†Ô∏è Fichier .env non trouv√© √† {env_path}")
        else:
            set_key(str(env_path), "HOYMILES_TOKEN", token)
            print("‚úÖ Token mis √† jour dans .env")

    elif mode == "gha":
        gha_env = getenv("GITHUB_ENV")
        if gha_env:
            with open(gha_env, "a", encoding="utf-8") as f:
                f.write(f"HOYMILES_TOKEN={token}\n")
            print("‚úÖ Token export√© dans $GITHUB_ENV")
        else:
            print("‚ö†Ô∏è Variable GITHUB_ENV non d√©finie ‚Äî impossible d‚Äôexporter le token.")

    return token


# ---------------------------------------------------------------------
# Fonctions HTTP (preview / export / download)
# ---------------------------------------------------------------------
def _get_headers(token: Optional[str] = None) -> dict:
    """
    Construit les en-t√™tes pour les requ√™tes Hoymiles.
    Le site attend le cookie/cl√© smc_prod_token ‚Üí donc 'authorization' brut.
    """
    tok = token or _current_token()
    if not tok:
        raise RuntimeError("‚ö†Ô∏è Aucun token disponible (HOYMILES_TOKEN non d√©fini).")
    return {
        "Accept": "application/json",
        "Content-Type": "application/json; charset=UTF-8",
        "Origin": "https://global.hoymiles.com",
        "Referer": "https://global.hoymiles.com/",
        "User-Agent": "Mozilla/5.0 (X11; Linux x86_64)",
        # Le cookie smc_prod_token se refl√®te c√¥t√© API comme 'authorization'
        "authorization": tok,
    }


def _get_cookies() -> dict:
    """Construit des cookies √† partir des variables d'environnement (si disponibles)."""
    return {
        "__hstc": getenv("HOYMILES_HSTC", ""),
        "hubspotutk": getenv("HOYMILES_HUBSPOT", ""),
        "_ga": getenv("HOYMILES_GA", ""),
        "_ga_61ZC562X9S": getenv("HOYMILES_GA61", "")
    }


def build_payload(site_id: int, date_str: str, quota: str|None="STATION_POWER") -> dict:
    """
    Construit et retourne un dictionnaire (payload) utilis√© pour interroger une API.

    Param√®tres
    ----------
    site_id : int
        Identifiant unique du site pour lequel la requ√™te doit √™tre effectu√©e.
    date_str : str
        Date au format texte (par exemple '2025-01-15') utilis√©e √† la fois comme
        date de d√©but et date de fin dans la requ√™te.
    quota : str
        Quota ("STATION_POWER" par d√©faut)

    Retour
    ------
    dict
        Un dictionnaire contenant les param√®tres n√©cessaires √† la requ√™te API :
        - sid_list : liste contenant l'identifiant du site
        - sid : identifiant unique du site
        - start_date : date de d√©but sous forme de cha√Æne
        - end_date : date de fin sous forme de cha√Æne
        - page : num√©ro de page (1 par d√©faut)
        - page_size : nombre d'√©l√©ments par page (20 par d√©faut)
    """

    # Construction du dictionnaire de param√®tres avec les valeurs fournies
    if quota is not None:
        payload = {
            "quota" : quota
        }
    else:
        payload = {}

    payload_common = {
        "sid_list": [site_id],  # La liste doit contenir l'identifiant du site
        "sid": site_id,  # Identifiant direct du site
        "start_date": date_str,  # Date de d√©but de la p√©riode
        "end_date": date_str,  # Date de fin de la p√©riode (identique ici)
        "page": 1,  # Premi√®re page par d√©faut
        "page_size": 20  # Taille de page par d√©faut
    }

    payload = dict(payload, **payload_common)

    # Retour du dictionnaire construit
    return payload


def request_production_preview(site_id: int, target_date: datetime) -> dict:
    """
    Appelle l'endpoint de pr√©visualisation (select_power_by_station).
    Retourne le JSON de la r√©ponse.
    """
    # 1Ô∏è‚É£ Datetime format to String
    date_str = format_date_to_str(target_date)

    resp = requests.post(
        API_BASE_URL + "select_power_by_station",
        headers=_get_headers(),
        cookies=_get_cookies(),
        json=build_payload(site_id=site_id, date_str=date_str, quota=None)
    )
    resp.raise_for_status()
    return resp.json()


def request_production_export(site_id: int, date_str: str) -> dict:
    """Effectue une requ√™te d'export de production Hoymiles pour une journ√©e donn√©e."""
    url = API_BASE_URL + "export_station_data"

    response = requests.post(
        url=url,
        headers=_get_headers(_current_token()),
        cookies=_get_cookies(),
        json=build_payload(site_id=site_id, date_str=date_str, quota="STATION_POWER"),
        timeout=30)

    data = response.json().get("data")
    resp = json.loads(response.text)

    if resp["message"] != "success":
        msg = resp["message"].lower()

        # VRAIES erreurs de token
        if any(x in msg for x in ["token", "verify", "unauthorized", "401", "403"]):
            raise RuntimeError("token error")

        # Operation error ‚Üí ce n'est PAS un token error
        if "operation error" in msg:
            raise RuntimeError(f"operation_error: {resp}")

        raise RuntimeError(f"Erreur Hoymiles pour {date_str}: {resp}")

    return data


def download_raw_production_zip_file(site_id: int,
                                     target_date: datetime,
                                     dest_dir: Path) -> Path:
    """
    T√©l√©charge l'archive ZIP produite par export_station_data pour une date donn√©e.
    - G√®re le polling tant que Hoymiles n'a pas encore g√©n√©r√© le fichier.
    - Retente automatiquement en cas de "Operation error" ou data=None.
    """
    # 1Ô∏è‚É£ Datetime format to String
    date_str = format_date_to_str(target_date)

    # 1Ô∏è‚É£ V√©rification de l'existence de donn√©es pour ce jour-l√†
    preview = request_production_preview(site_id, target_date)
    if preview.get('message') != 'success':
        raise RuntimeError(f"√âchec : aucune donn√©e pour {date_str} (r√©ponse preview: {preview.get('message')})")

    # 2Ô∏è‚É£ Lancement de l'export
    export_resp = request_production_export(site_id, date_str)
    # 3Ô∏è‚É£ T√©l√©chargement du ZIP
    DATA_FOLDER.mkdir(parents=True, exist_ok=True)
    chemin_zip = dest_dir.joinpath(f"station_power_{date_str}.zip")
    print(f"üì¶ T√©l√©chargement de l'archive {export_resp.get('file_name')}")
    r = requests.get(export_resp.get('url'), timeout=90)
    r.raise_for_status()
    with open(chemin_zip, "wb") as fh:
        fh.write(r.content)

    print(f"‚úÖ Archive t√©l√©charg√©e : {chemin_zip}")
    return chemin_zip


def fetch_and_archive(target_date: datetime, site_id: int, archive_path: Path, csv_path_30min: Path, csv_path_1h: Path) -> bool:
    """
    T√©l√©charge et int√®gre les donn√©es de production pour une date donn√©e.
    Optimis√© pour √©viter les t√©l√©chargements et traitements inutiles.

    Param√®tres :
        target_date (datetime) : date cible
        site_id (int) : identifiant de la station Hoymiles
        archive_path (Path) : chemin du fichier ZIP d‚Äôarchive (raw_prod_files.zip)
        csv_path_30min (Path) : chemin du fichier CSV cumulatif moyenn√© sur 30min
        csv_path_1h (Path) : chemin du fichier CSV cumulatif moyenn√© sur 1h

    Retourne :
        bool : True si de nouvelles donn√©es ont √©t√© t√©l√©charg√©es, False sinon
    """

    # ----------------------------------------------------------
    # 1) V√©rification : le fichier existe-t-il d√©j√† dans le ZIP ?
    # ----------------------------------------------------------

    zip_filename = "prod_" + target_date.strftime("%Y-%m-%d") + ".csv"
    already_in_zip = False

    if archive_path.exists():
        with zipfile.ZipFile(archive_path, "r") as z:
            already_in_zip = zip_filename in z.namelist()

    # ----------------------------------------------------------
    # 2) V√©rification : donn√©es pr√©sentes dans les resampl√©s ?
    # ----------------------------------------------------------

    if already_in_zip:
        has_data = resampled_data_exists_for_date(target_date=target_date,
                                                  csv_30min=csv_path_30min, csv_1h=csv_path_1h)

        if has_data:
            print(f"‚è© Donn√©es d√©j√† int√©gr√©es pour {target_date.date()} ‚Äî aucune action n√©cessaire.")
            return True

        print(f"‚ôªÔ∏è Donn√©es d√©j√† dans le ZIP mais resamplages manquants ‚Üí reconstruction‚Ä¶")

        # Dans ce cas : lire les donn√©es du ZIP
        df = read_csv_from_zip(zip_path=archive_path, zip_filename=zip_filename)
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".csv")
        df.to_csv(tmp.name, sep=";", index=False)

        append_csvs_with_resampling(
            csv_paths=[Path(tmp.name)],
            csv_30min=csv_path_30min,
            csv_1h=csv_path_1h
        )

        return True

    # ----------------------------------------------------------
    # 3) Sinon ‚Üí t√©l√©chargement normal
    # ----------------------------------------------------------

    temp_dir = tempfile.TemporaryDirectory()
    temp_file = Path(temp_dir.name)

    try:
        try:
            zip_path = download_raw_production_zip_file(
                site_id=site_id,
                target_date=target_date,
                dest_dir=temp_file
            )
        except Exception as e:
            msg = str(e).lower()

            is_token_issue = any(x in msg for x in ["token error", "401", "403", "verify"])
            is_operation_error = "operation_error" in msg  # ce qu‚Äôon renvoie depuis request_production_export

            if is_token_issue and not is_operation_error:
                print("‚ö†Ô∏è Probl√®me de token ‚Äî tentative de rafra√Æchissement‚Ä¶")
                new_token = refresh_token(mode="gha" if getenv("GITHUB_ACTIONS") else "local")
                if not new_token:
                    raise RuntimeError("‚ùå Impossible de rafra√Æchir le token Hoymiles.")

                # üîÅ Second essai
                try:
                    zip_path = download_raw_production_zip_file(
                        site_id=site_id,
                        target_date=target_date,
                        dest_dir=temp_file
                    )
                except Exception as e2:
                    raise RuntimeError(f"token error apr√®s refresh: {e2}")

            else:
                raise

        # Extraction du CSV brut
        csv_extracted = extract_csv_from_zip(zip_path=zip_path, dest_folder=temp_file)

        # Renommage des colonnes Hoymiles
        prod_csv_map = {"Time": "datetime", "Production (W)": "production"}
        clean_csv_columns(source_csv=csv_extracted, columns_map=prod_csv_map)

        # Ajout √† l‚Äôarchive
        add_file_to_zip(tmp_file=csv_extracted,
                        zip_path=archive_path,
                        target_date=target_date)

        # Mise √† jour des fichiers resampl√©s
        append_csvs_with_resampling(
            csv_paths=[csv_extracted],
            csv_30min=csv_path_30min,
            csv_1h=csv_path_1h
        )

        print(f"‚úÖ Donn√©es de production int√©gr√©es pour {target_date.date()}")
        sleep(1)
        return True

    except Exception as e:
        print(f"‚ùå Erreur lors du traitement de {target_date.date()} : {e}")
        return False

    finally:
        shutil.rmtree(temp_file, ignore_errors=True)

    # temp_dir = tempfile.TemporaryDirectory()
    # temp_file = Path(temp_dir.name)
    # try:
    #     try:
    #         zip_path = download_raw_production_zip_file(site_id=site_id,
    #                                                     target_date=target_date,
    #                                                     dest_dir=temp_file)
    #     except Exception as e:
    #         msg = str(e).lower()
    #         if "token error" in msg or "401" in msg or "403" in msg or "verify" in msg:
    #             print("‚ö†Ô∏è Probl√®me de token d√©tect√© ‚Äî tentative de rafra√Æchissement...")
    #             new_token = refresh_token(mode="gha" if getenv("GITHUB_ACTIONS") else "local")
    #             if not new_token:
    #                 raise RuntimeError("‚ùå Impossible de rafra√Æchir le token Hoymiles.")
    #             zip_path = download_raw_production_zip_file(site_id=site_id,
    #                                                         target_date=target_date,
    #                                                         dest_dir=temp_file)
    #         else:
    #             raise
    #
    #     csv_extracted = extract_csv_from_zip(zip_path=zip_path,
    #                                          dest_folder=temp_file)
    #     # Mapping des colonnes Hoymiles
    #     prod_csv_map = {
    #         "Time": "datetime",
    #         "Production (W)": "production",
    #     }
    #     # Extraction, et renommage des colonnes du fichier csv
    #     clean_csv_columns(source_csv=csv_extracted, columns_map=prod_csv_map)
    #     # Renommage du fichier csv et ajout √† l'archive
    #     add_file_to_zip(tmp_file=csv_extracted, zip_path=archive_path, target_date=target_date)
    #     append_csvs_with_resampling(csv_paths=[csv_extracted],
    #                                 csv_30min=csv_path_30min,
    #                                 csv_1h=csv_path_1h)
    #     print(f"‚úÖ Donn√©es de production int√©gr√©es pour {target_date}")
    #     sleep(1)  # pour √©viter la surcharge de l'API
    #     return True
    #
    # except Exception as e:
    #     print(f"‚ùå Erreur lors du traitement de {target_date} : {e}")
    #     return False
    #
    # finally:
    #     shutil.rmtree(temp_file, ignore_errors=True)
